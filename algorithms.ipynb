{
 "metadata": {
  "name": "",
  "signature": "sha256:170ed3e03328eeffc9120b8fb1bc852f4f18863a6249b081757cc41a8302fa3e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
      "import numpy as np\n",
      "from sklearn import preprocessing\n",
      "from sklearn.svm import SVR\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.cluster import MiniBatchKMeans\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "import time\n",
      "from data_encoding import train_test\n",
      "from sklearn.svm import SVR\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.ensemble import GradientBoostingRegressor\n",
      "\n",
      "def label_encoder(data, binary_cols):\n",
      "    label_enc = LabelEncoder()\n",
      "\n",
      "    for col in binary_cols:\n",
      "        label_enc.fit(data[col])\n",
      "        data[col] = label_enc.transform(data[col])\n",
      "    encoded_binary = np.array(data[binary_cols])\n",
      "    return  encoded_binary\n",
      "\n",
      "\n",
      "def dummy_encoder(train_X,test_X,categorical_variable_list):\n",
      "    enc = OneHotEncoder(n_values ='auto',categorical_features=categorical_variable_list)\n",
      "    train_X = enc.fit_transform(train_X).toarray()\n",
      "    test_X = enc.transform(test_X).toarray()\n",
      "    return train_X, test_X\n",
      "\n",
      "\n",
      "\n",
      "def normalize(X):\n",
      "    normalizer = preprocessing.Normalizer().fit(X)\n",
      "    normalized_X = normalizer.transform(X)\n",
      "    return normalized_X\n",
      "\n",
      "\n",
      "def category_manipulation(train,test):\n",
      "    vect = CountVectorizer(tokenizer=lambda text: text.split(','))\n",
      "    \n",
      "    cat_fea = vect.fit_transform(train['categories'].fillna(''))\n",
      "    cat_fea = cat_fea.todense()\n",
      "    idx_max_1 = cat_fea > 1\n",
      "    cat_fea[idx_max_1] = 1\n",
      "    \n",
      "    cat_fea_test = vect.transform(test['categories'].fillna(''))\n",
      "    cat_fea_test = cat_fea_test.todense()\n",
      "    idx_max_1 = cat_fea_test > 1\n",
      "    cat_fea_test[idx_max_1] = 1\n",
      "    \n",
      "    # CATEGORY CLUSTERS\n",
      "    #  Based on the category extracted before, the idea is to create a n clusters to\n",
      "    #  aggregate set of similar categories\n",
      "    for esti in (2,3,5):#,60,70,80,90,100,110,125):\n",
      "        km = MiniBatchKMeans(n_clusters=esti, random_state=888)#, init_size=esti*10)\n",
      "    #       init='k-means++', n_clusters=3, n_init=10\n",
      "        print \"fitting \"+str(esti)+\" clusters - category\"\n",
      "        init_time = time.time()\n",
      "        km.fit(cat_fea)\n",
      "        print (time.time()-init_time)/60\n",
      "\n",
      "        train['cat_clust_'+str(esti)] = km.predict(cat_fea)\n",
      "        test['cat_clust_'+str(esti)] = km.predict(cat_fea_test)\n",
      "    train['cat_clust_2'] = km.predict(cat_fea)\n",
      "    test['cat_clust_2'] = km.predict(cat_fea_test)\n",
      "    return train,test\n",
      "\n",
      "\n",
      "def train_test():\n",
      "\n",
      "    train = pd.read_csv('train_new.csv', header=0)\n",
      "    pred = pd.read_csv('test_new.csv', header=0)\n",
      "    \n",
      "#     print train['zip_code']\n",
      "    \n",
      "    train, pred = category_manipulation(train, pred)\n",
      "    \n",
      "    # print train.columns.values\n",
      "    review_id = pred['review_id']\n",
      "    \n",
      "\n",
      "    del train[\"business_id\"], train[\"date\"], train[\"review_id\"], train[\"text\"], train[\"type_x\"], train[\"user_id\"],\\\n",
      "        train[\"votes_cool_x\"], train[\"votes_funny_x\"],train[\"full_address\"], train[\"latitude\"], train[\"longitude\"],\\\n",
      "        train[\"name_x\"], train[\"neighborhoods\"], train[\"type_y\"], train[\"name_y\"], train[\"type\"], train[\"votes_cool_y\"],\\\n",
      "        train[\"votes_funny_y\"], train[\"votes_useful_y\"], train[\"state\"], train[\"city\"],train[\"categories\"]\n",
      "\n",
      "    #print test.columns.values\n",
      "    del pred[\"business_id\"], pred[\"date\"], pred[\"review_id\"], pred[\"text\"], pred[\"type_x\"], pred[\"user_id\"],\\\n",
      "        pred[\"full_address\"], pred[\"latitude\"], pred[\"longitude\"],\\\n",
      "        pred[\"name_x\"], pred[\"neighborhoods\"], pred[\"type_y\"], pred[\"name_y\"], pred[\"type\"], pred[\"state\"], pred[\"city\"],pred[\"categories\"]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    ### Vectorizing  ZIP\n",
      "#     vect = CountVectorizer()#tokenizer=lambda text: text.split(','))\n",
      "# #     zip_fea = vect.fit_transform(train['zip_code']).fillna('')\n",
      "#     zip_fea = vect.fit_transform(train['zip_code'].fillna(''))\n",
      "#     # print zip_fea\n",
      "#     zip_fea = zip_fea.todense()\n",
      "#     # print zip_fea\n",
      "#     idx_max_1 = zip_fea > 1\n",
      "#     zip_fea[idx_max_1] = 1\n",
      "#     zip_fea_test = vect.transform(pred['zip_code'])\n",
      "#     zip_fea_test = zip_fea_test.todense()\n",
      "#     idx_max_1 = zip_fea_test > 1\n",
      "#     zip_fea_test[idx_max_1] = 1\n",
      "\n",
      "\n",
      "#     km = MiniBatchKMeans(n_clusters=100, random_state=1377, init_size=100*10)\n",
      "\n",
      "#     km.fit(zip_fea)\n",
      "#     train['zip_clust'] = km.predict(zip_fea)\n",
      "#     pred['zip_clust'] = km.predict(zip_fea_test)\n",
      "\n",
      "    #deleting actual zip codes\n",
      "#     del train['zip_code'], pred['zip_code']\n",
      "\n",
      "\n",
      "\n",
      "    # print train.head()\n",
      "    # print pred.head()\n",
      "\n",
      "    target = np.array(train[\"votes_useful_x\"])\n",
      "    target_var = [\"votes_useful_x\"]\n",
      "    binary_var = [\"open\"]\n",
      "    categorical_var = [\"cat_clust_2\",\"zip_code\",\"user_id_cluster_125\"]\n",
      "\n",
      "\n",
      "    col_names_train= train.columns.values\n",
      "    col_names_pred = pred.columns.values\n",
      "\n",
      "    numerical_var = [col for col in col_names_train if col not in binary_var if col not in categorical_var if col not in target_var]\n",
      "    numerical_var_pred = [col for col in col_names_pred if col not in binary_var if col not in categorical_var]\n",
      "    # encoded_categorical, encoded_binary = label_encoder(train, binary_var, categorical_var)\n",
      "    # encoded_categorical_pred, encoded_binary_pred= label_encoder(pred, binary_var, categorical_var)\n",
      "    encoded_binary = label_encoder(train, binary_var)\n",
      "    encoded_binary_pred= label_encoder(pred, binary_var)\n",
      "\n",
      "    categorical_variables = np.array(train[categorical_var])\n",
      "    categorical_variables_pred = np.array(pred[categorical_var])\n",
      "    numerical_data = np.array(train[numerical_var])\n",
      "    numerical_data_pred = np.array(pred[numerical_var_pred])\n",
      "\n",
      "\n",
      "    training_data_transformed = np.concatenate((categorical_variables,encoded_binary,numerical_data),axis=1)\n",
      "    pred_data_transformed = np.concatenate((categorical_variables_pred,encoded_binary_pred,numerical_data_pred),axis=1)\n",
      "\n",
      "\n",
      "\n",
      "    train_x = training_data_transformed\n",
      "    train_y = target\n",
      "    pred_x = pred_data_transformed\n",
      "\n",
      "    #pd.DataFrame(pred_x).to_csv(\"test_labelenc.csv\")\n",
      "\n",
      "    #REMEMBER TO ENCODE THE CATEGORICAL VARS\n",
      "    # print train_x[1:5],\n",
      "    train_x, pred_x = dummy_encoder(train_x, pred_x, categorical_variable_list = list(range(0,1,1)))\n",
      "    # print train_x[0:5,], test_x[0:5,]\n",
      "\n",
      "    #normalizing (if required)\n",
      "    train_x_norm = normalize(train_x)\n",
      "    #test_x_norm = normalize(test_x)\n",
      "    pred_x_norm = normalize(pred_x)\n",
      "\n",
      "\n",
      "    return train_x, train_y,train_x_norm, pred_x, pred_x_norm, review_id\n",
      "\n",
      "\n",
      "# train_test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_x, train_y,train_x_norm, pred_x, pred_x_norm, review_id = train_test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fitting 2 clusters - category\n",
        "0.0269853989283"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fitting 3 clusters - category"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0279889027278"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "fitting 5 clusters - category"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0284171700478"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "no supported conversion for types: (dtype('float64'), dtype('O'))",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-26-7fee844b02e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_x_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-25-3cebc4da0bde>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m#REMEMBER TO ENCODE THE CATEGORICAL VARS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# print train_x[1:5],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_variable_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;31m# print train_x[0:5,], test_x[0:5,]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-25-3cebc4da0bde>\u001b[0m in \u001b[0;36mdummy_encoder\u001b[0;34m(train_X, test_X, categorical_variable_list)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdummy_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategorical_variable_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_values\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_variable_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/RashmiSaurabh/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \"\"\"\n\u001b[1;32m   1053\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 1054\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/RashmiSaurabh/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_not_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_not_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_not_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/RashmiSaurabh/anaconda/lib/python2.7/site-packages/scipy/sparse/construct.pyc\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[0;32m--> 453\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/RashmiSaurabh/anaconda/lib/python2.7/site-packages/scipy/sparse/construct.pyc\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0mrow_offsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/RashmiSaurabh/anaconda/lib/python2.7/site-packages/scipy/sparse/sputils.pyc\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('float64'), dtype('O'))"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "def rsmle_(predicted,actual):\n",
      "   return np.sqrt(np.mean((pow(np.log(predicted+1) - np.log(actual+1),2))))\n",
      "\n",
      "def support_vector_regressor(X_train, y_train):\n",
      "    clf = SVR()\n",
      "    clf.fit(X_train, y_train)\n",
      "    # plot_learning_curve(clf, title =\"Support Vector learning curve\", X = X_train,y = y_train, ylim=(0, 1.1))\n",
      "    #y_pred_SVC = clf.predict(X_train)\n",
      "    #print clf.predict(X_train)\n",
      "    pd.DataFrame(clf.predict(X_train)).to_csv(\"y_pred_svr.csv\")\n",
      "    print np.sqrt(np.mean((pow(np.log(clf.predict(X_train)+1) - np.log(y_train+1),2))))\n",
      "    # plot_validation_curve(clf,title =\"Support Vector Classifier validation curve\", X=X_train, y=y_train,param_name='C', param_range = [1, 5, 20, 50])\n",
      "    # print y_train, y_pred_SVC\n",
      "    # print clf.score(X_train, y_train)\n",
      "    # # cross_validation_accuracy= cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'accuracy').mean()\n",
      "    # print \"Support Vector Classifier : Training set metrics\"\n",
      "    # print \"Cross validation accuracy:\", cross_validation_accuracy\n",
      "    # print_metrics(y_train, y_pred_SVC)\n",
      "    # file = open(\"SVM_clf.p\", \"wb\")\n",
      "    # pickle.dump(clf, file)\n",
      "    # file.close()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    train_x, train_y,train_x_norm, pred_x, pred_x_norm, review_id = train_test()\n",
      "\n",
      "    print \"data fetched...\"\n",
      "\n",
      "    rf = RandomForestRegressor()\n",
      "    rf.fit(train_x, train_y)\n",
      "    # print rf.score(train_x, train_y)\n",
      "    Votes = rf.predict(pred_x)\n",
      "    Id = np.array(review_id)\n",
      "    print len(Votes), len(Id)\n",
      "    df = pd.DataFrame(Votes,Id)\n",
      "    df.to_csv(\"submission_rf.csv\", engine=\"python\")\n",
      "    print \"rf done\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    # list_data = [Id,Votes]\n",
      "    # submission_rf = pd.concat(list_data)\n",
      "    # submission_rf= np.concatenate((Id,Votes),axis=0)\n",
      "    # print submission_rf\n",
      "    # # np.savetxt(\"rf_predicted.csv\", submission_rf, delimiter=',',fmt=\"%s\")\n",
      "    # # pd.DataFrame(bus_id,rf.predict(pred_x)).to_csv(\"rf_predicted.csv\")\n",
      "\n",
      "\n",
      "    # print rf.score(train_x,train_y)\n",
      "    # print rf.score(test_x,test_y)\n",
      "    # print \"RMSE rf:\",rsmle_(rf.predict(pred_x))\n",
      "    #print train_x[1:5,], train_y[1:5], test_x[1:5,],test_y[1:5]\n",
      "    # support_vector_regressor(train_x_norm,train_y)\n",
      "\n",
      "    # gbr = GradientBoostingRegressor()\n",
      "    # gbr.fit(train_x, train_y)\n",
      "    # print gbr.score(train_x, train_y)\n",
      "    # Votes = pd.DataFrame(gbr.predict(pred_x))\n",
      "    # Id = bus_id\n",
      "    # print pd.concat(Id,Votes)\n",
      "    # pd.concat(Id,Votes).to_csv(\"gbr_predicted.csv\")\n",
      "    # print \"gbr done\"\n",
      "\n",
      "    # print \"RMSE gbr:\", rsmle_(gbr.predict(test_x),test_y)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sn = pd.read_table(\"stupidNAs.csv\",sep=\",\")\n",
      "sn.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>stars_x</th>\n",
        "      <th>votes_useful_x</th>\n",
        "      <th>freshness</th>\n",
        "      <th>text_length</th>\n",
        "      <th>count_adj</th>\n",
        "      <th>count_punct</th>\n",
        "      <th>open</th>\n",
        "      <th>review_count_x</th>\n",
        "      <th>stars_y</th>\n",
        "      <th>zip_code</th>\n",
        "      <th>cat_clust_2</th>\n",
        "      <th>loc_clust_5</th>\n",
        "      <th>total_checkins</th>\n",
        "      <th>average_stars</th>\n",
        "      <th>review_count_y</th>\n",
        "      <th>user_id_cluster_125</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> 5</td>\n",
        "      <td> 5</td>\n",
        "      <td>  724</td>\n",
        "      <td>  889</td>\n",
        "      <td> 10</td>\n",
        "      <td>  3</td>\n",
        "      <td>  True</td>\n",
        "      <td> 116</td>\n",
        "      <td> 4.0</td>\n",
        "      <td> 85042</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 114</td>\n",
        "      <td> 3.72</td>\n",
        "      <td> 376</td>\n",
        "      <td> 106</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> 4</td>\n",
        "      <td> 2</td>\n",
        "      <td>  865</td>\n",
        "      <td> 1583</td>\n",
        "      <td> 21</td>\n",
        "      <td>  7</td>\n",
        "      <td>  True</td>\n",
        "      <td> 109</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 85042</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>  36</td>\n",
        "      <td> 3.72</td>\n",
        "      <td> 376</td>\n",
        "      <td> 106</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td>  810</td>\n",
        "      <td>  766</td>\n",
        "      <td>  6</td>\n",
        "      <td> 11</td>\n",
        "      <td>  True</td>\n",
        "      <td> 189</td>\n",
        "      <td> 4.5</td>\n",
        "      <td> 85004</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2</td>\n",
        "      <td> 270</td>\n",
        "      <td> 3.72</td>\n",
        "      <td> 376</td>\n",
        "      <td> 106</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "      <td> 2</td>\n",
        "      <td> 1033</td>\n",
        "      <td>  989</td>\n",
        "      <td> 11</td>\n",
        "      <td> 12</td>\n",
        "      <td> False</td>\n",
        "      <td>  39</td>\n",
        "      <td> 3.5</td>\n",
        "      <td> 85254</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>  68</td>\n",
        "      <td> 3.72</td>\n",
        "      <td> 376</td>\n",
        "      <td> 106</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4</td>\n",
        "      <td> 3</td>\n",
        "      <td> 0</td>\n",
        "      <td>  990</td>\n",
        "      <td> 2647</td>\n",
        "      <td> 45</td>\n",
        "      <td> 16</td>\n",
        "      <td>  True</td>\n",
        "      <td> 262</td>\n",
        "      <td> 4.0</td>\n",
        "      <td> 85251</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 750</td>\n",
        "      <td> 3.72</td>\n",
        "      <td> 376</td>\n",
        "      <td> 106</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "   Unnamed: 0  stars_x  votes_useful_x  freshness  text_length  count_adj  \\\n",
        "0           0        5               5        724          889         10   \n",
        "1           1        4               2        865         1583         21   \n",
        "2           2        3               1        810          766          6   \n",
        "3           3        2               2       1033          989         11   \n",
        "4           4        3               0        990         2647         45   \n",
        "\n",
        "   count_punct   open  review_count_x  stars_y zip_code  cat_clust_2  \\\n",
        "0            3   True             116      4.0    85042            0   \n",
        "1            7   True             109      3.5    85042            0   \n",
        "2           11   True             189      4.5    85004            1   \n",
        "3           12  False              39      3.5    85254            1   \n",
        "4           16   True             262      4.0    85251            0   \n",
        "\n",
        "   loc_clust_5  total_checkins  average_stars  review_count_y  \\\n",
        "0            0             114           3.72             376   \n",
        "1            0              36           3.72             376   \n",
        "2            2             270           3.72             376   \n",
        "3            1              68           3.72             376   \n",
        "4            0             750           3.72             376   \n",
        "\n",
        "   user_id_cluster_125  \n",
        "0                  106  \n",
        "1                  106  \n",
        "2                  106  \n",
        "3                  106  \n",
        "4                  106  "
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sn[pd.isnull(sn['total_checkins'])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>stars_x</th>\n",
        "      <th>votes_useful_x</th>\n",
        "      <th>freshness</th>\n",
        "      <th>text_length</th>\n",
        "      <th>count_adj</th>\n",
        "      <th>count_punct</th>\n",
        "      <th>open</th>\n",
        "      <th>review_count_x</th>\n",
        "      <th>stars_y</th>\n",
        "      <th>zip_code</th>\n",
        "      <th>cat_clust_2</th>\n",
        "      <th>loc_clust_5</th>\n",
        "      <th>total_checkins</th>\n",
        "      <th>average_stars</th>\n",
        "      <th>review_count_y</th>\n",
        "      <th>user_id_cluster_125</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "Empty DataFrame\n",
        "Columns: [Unnamed: 0, stars_x, votes_useful_x, freshness, text_length, count_adj, count_punct, open, review_count_x, stars_y, zip_code, cat_clust_2, loc_clust_5, total_checkins, average_stars, review_count_y, user_id_cluster_125]\n",
        "Index: []"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}